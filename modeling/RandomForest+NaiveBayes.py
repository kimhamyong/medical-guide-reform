# -*- coding: utf-8 -*-
"""ML_Project_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zi_tBuR_qfo8OQtYcDikp_q4BT2MBXWV
"""

!pip install kiwipiepy
!pip install --force-reinstall torch==2.6.0

!pip install --force-reinstall numpy==2.0.2
!pip install --force-reinstall bert-score==0.3.13
!pip install --force-reinstall evaluate==0.4.3 sacremoses==0.1.1 sacrebleu==2.5.1

# ----------------------------------------
# Requirements (Install before use)
# ----------------------------------------
# !pip install matplotlib scikit-learn
# !pip install bert-score
# !pip install evaluate sacremoses sacrebleu

# Version Info:
# matplotlib==3.10.0
# scikit-learn==1.6.1
# bert-score==0.3.13
# evaluate==0.4.3
# sacremoses==0.1.1
# sacrebleu==2.5.1
# torch==2.6.0
# transformers==4.52.2
# pandas==2.2.2
# numpy==2.0.2
# tqdm==4.67.1
# requests==2.32.3

# ----------------------------------------
# Models and Evaluation Metrics (via Hugging Face)
# ----------------------------------------
# BERTScore: google-bert/bert-base-multilingual-cased
# SARI: evaluate-metric/sari
# ----------------------------------------
import numpy as np
from bert_score import score
import evaluate

def compute_avg_sentence_length(sentences):
    if not sentences:
        return 0.0
    word_counts = [len(sentence.split()) for sentence in sentences]
    avg_length = sum(word_counts) / len(word_counts)
    return avg_length

def compute_bertscore(originals, rewrites, model_type='bert-base-multilingual-cased'):
    P, R, F1 = score(cands=rewrites, refs=originals, lang="ko", model_type=model_type, rescale_with_baseline=True)
    return float(F1.mean())

sari_metric = evaluate.load("sari")

def compute_sari(originals, rewrites, references):
    scores = []
    for src, pred, ref in zip(originals, rewrites, references):
        result = sari_metric.compute(
            predictions=[pred],
            references=[[ref]],
            sources=[src]
        )
        scores.append(result['sari'])
    return sum(scores) / len(scores)

def print_originals_and_rewrites(originals, rewrites):
    for i, (ori, rewrite) in enumerate(zip(originals, rewrites)):
        print(f"[{i+1}] Original : {ori}")
        print(f"[{i+1}] Rewrite  : {rewrite}")
        print("-" * 40)


def print_model_report(model_name, f1, avg_len, sari):
    """
    평가 결과를 출력합니다.
    - f1: BERTScore (float)
    - avg_len: 평균 문장 길이 (float)
    - sari: SARI 점수 (float)
    """
    print(f"평가 결과 - {model_name}")
    print(f"──────────────────────────────")
    print(f"KoBERTScore:     {f1:.4f}")
    print(f"SARI Score:      {sari:.2f}")
    print(f"평균 문장 길이:   {avg_len:.2f} 단어")
    print(f"──────────────────────────────")

def evaluate_model(originals, rewrites, references, model_name='MyModel'):
    """
    전체 평가 흐름을 통합 실행합니다.

    Parameters:
    - originals: 원본 문장 리스트
    - rewrites: 모델이 생성한 문장 리스트
    - references: 정답 문장 리스트 -> `original_text`에 대응되는 `simple_text`를 참조하여 구성해야 함.
    - model_name: 출력 시 모델 이름

    Returns:
    - dict: 평가 결과 (BERTScore, SARI, 평균 문장 길이)
    """
    bertscore = compute_bertscore(originals, rewrites)
    avg_len = compute_avg_sentence_length(rewrites)
    sari = compute_sari(originals, rewrites, references)

    print_model_report(model_name, bertscore, avg_len, sari)
    print_originals_and_rewrites(originals, rewrites)

from google.colab import drive # 구글 드라이브 연결
drive.mount('/content/drive')

csv_file_path = "./drive/MyDrive/combined_dataset.csv"

import pandas as pd
data = pd.read_csv(csv_file_path, sep=",")
data.head()

with open(stop_words_path, "r", encoding="UTF-8") as inFile:
  lines = inFile.readlines()

stop_words = set([])
for line in lines:
  stop_words.add(line.replace("\n",""))



from kiwipiepy import Kiwi
from kiwipiepy.utils import Stopwords
import re
# Kiwi의 객체 생성
kiwi = Kiwi()
stopwords = Stopwords()

def preprocessing(kiwi, review):
  # 한글이 아닌 단어는 지우고 " "으로 대체
  review_text = re.sub(r'[^ㄱ-ㅎ가-힣]+', ' ', review)

  token_list = kiwi.tokenize(review_text, stopwords=stopwords) # 받침 분리 안함 + stopwords
  # 초성에 해당하지 않는 단어만 clean_review에 들어갈 수 있게 함
  clean_review = []
  for token in token_list:
    if not token[1] == 'ETM' and not token[1] == 'EF':
      # if token[1] == 'EF': # 됩니다. 하십시오. 등은 되다. 하오. 로 전처리 하기위함
      #   clean_review[-1] += token[0][-1]
      # else:
      #   clean_review.append(token[0])
      clean_review.append(token[0])
  # 단어들을 ' '기준으로 이어 붙혀서 하나의 string 타입의 변수를 생성함
  clean_review = ' '.join(clean_review)

  # 전처리 완료된 문장을 return
  return clean_review.strip()

df = data
df['preprocessing_text'] = df['original_text'].apply(lambda t : preprocessing(kiwi, t))

df.head()

preprocessing_kiwi = df

preprocessing_kiwi.head()

# 나이브 베이즈
from sklearn.model_selection import train_test_split
# train_test_split으로 분할
df_train, df_test = train_test_split(preprocessing_kiwi, test_size=0.1, random_state=42)
# 훈련 데이터
x_train = df_train['preprocessing_text'] # 실제 학습에 쓰일 x데이터 -> 전처리된 텍스트를 기반으로 한다.
origin_train = df_train['original_text'] # 성능 평가에 쓰일 원본 데이터 -> 훈련 데이터는 안쓰므로 사실 필요 없음
y_train = df_train['simple_text'] # y 데이터 -> 미리 만들어둔 심플 데이터를 사용
# 테스트 데이터
x_test =  df_test['preprocessing_text'] # 훈련데이터와 동일
origin_test = df_test['original_text']
y_test = df_test['simple_text']

# bow
from sklearn.feature_extraction.text import CountVectorizer
bow_vectorizer = CountVectorizer(analyzer='word', max_features=1000)
# train
x_train_bow = bow_vectorizer.fit_transform(x_train)
# test
x_test_bow = bow_vectorizer.transform(x_test)

# tfidf
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer()
#train
x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)
#test
x_test_tfidf = tfidf_vectorizer.transform(x_test)

from sklearn.naive_bayes import MultinomialNB # 나이브웨이즈 모델 사용

modBow = MultinomialNB(alpha=1.0) # MultinomialNB 객체 생성
modTfidf = MultinomialNB(alpha=1.0)
# 모델 학습
modBow.fit(x_train_bow,y_train)
modBowPred = modBow.predict(x_test_bow)
print(modBow.predict(bow_vectorizer.transform(["전신 마취 후 당일 은 심호흡을 자주 합니다."])))

modTfidf.fit(x_train_tfidf,y_train)
modTfidfPred = modTfidf.predict(x_test_tfidf)
print(modTfidf.predict(tfidf_vectorizer.transform(["전신 마취 후 당일 은 심호흡을 자주 합니다."])))

from sklearn.ensemble import RandomForestClassifier # 랜덤포레스트 사용

randomForestBow = RandomForestClassifier() # RandomForestClassifier 객체 생성
randomForestTfidf = RandomForestClassifier()

# 모델 학습
randomForestBow.fit(x_train_bow, y_train)
randomForestBowPred = randomForestBow.predict(x_test_bow)
print(randomForestBow.predict(bow_vectorizer.transform(["전신 마취 후 당일 은 심호흡을 자주 합니다."])))

randomForestTfidf.fit(x_train_tfidf, y_train)
randomForestTfidfPred = randomForestTfidf.predict(x_test_tfidf)
print(randomForestTfidf.predict(tfidf_vectorizer.transform(["전신 마취 후 당일 은 심호흡을 자주 합니다."])))

evaluate_model(list(origin_test.values), list(modBowPred), list(y_test.values), "Naive_bow")

evaluate_model(list(origin_test.values), list(modTfidfPred), list(y_test.values), "Naive_tfidf")

evaluate_model(list(origin_test.values), list(randomForestBowPred), list(y_test.values), "RandomForest_bow")

evaluate_model(list(origin_test.values), list(randomForestTfidfPred), list(y_test.values), "RandomForest_tfidf")

