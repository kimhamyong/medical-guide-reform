# -*- coding: utf-8 -*-
"""RandomForest+NaiveBayes_okt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GKuEW9EgHejYOwG-MQ8UXPYGT0X8xyQ4
"""

# 설치
!pip install bert-score evaluate sacremoses sacrebleu

# 1) Java 설치 (Okt가 Java를 필요로 함)
!apt-get update -qq
!apt-get install -y openjdk-8-jdk-headless -qq

# 2) konlpy 설치
!pip install konlpy --quiet

from google.colab import drive
drive.mount('/content/drive')

import re
import pandas as pd
from konlpy.tag import Okt

# 1) Okt 객체 한 번만 생성
okt = Okt()

# 2) 한글, 숫자, 영어만 남기고 특수문자 제거 + 공백 제거
def clean_text_keep_kor_eng_num(text):
    # 한글, 숫자, 영어, 공백만 남기기
    cleaned = re.sub(r'[^ㄱ-ㅎ가-힣a-zA-Z0-9\s]', '', str(text))
    return cleaned.strip()

# 3) 전체 CSV 파일 전처리 함수
def preprocess_dataset(csv_path):
    """
    Returns:
        pd.DataFrame:
          - original_preprocessed: original_text에서 한글+영어+숫자만 남기고 공백 제거
          - simple_preprocessed:   simple_text에서 한글+영어+숫자만 남기고 공백 제거
    """
    df = pd.read_csv(csv_path, encoding='cp949')

    df['original_preprocessed'] = df['original_text'].apply(clean_text_keep_kor_eng_num)
    df['simple_preprocessed']   = df['simple_text'].apply(clean_text_keep_kor_eng_num)

    # 빈 문자열 제거
    df = df[df['original_preprocessed'].str.strip() != '']
    df = df[df['simple_preprocessed'].str.strip() != '']

    return df

# 파일 경로
csv_path = "/content/drive/MyDrive/combined_dataset.csv"

# 전처리 실행
df = preprocess_dataset(csv_path)

# 결과 확인
print("전처리 완료, 샘플 보기:")
print(df[['original_preprocessed', 'simple_preprocessed']].head())

from sklearn.model_selection import train_test_split

# 2-1) 전체 데이터를 9:1로 나눔
train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)

# 2-2) 학습용 X, y
X_train = train_df["original_preprocessed"].tolist()
y_train = train_df["simple_preprocessed"].tolist()

# 2-3) 테스트용 X, y
X_test  = test_df["original_preprocessed"].tolist()
y_test  = test_df["simple_preprocessed"].tolist()

# 2-4) 원본 평가용 (원문 그대로 출력해 보기 위해)
orig_test = test_df["original_text"].tolist()

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier

# 3-1) CountVectorizer + NaiveBayes
bow = CountVectorizer(max_features=1000)
X_train_bow = bow.fit_transform(X_train)
X_test_bow  = bow.transform(X_test)

nb_bow = MultinomialNB(alpha=1.0)
nb_bow.fit(X_train_bow, y_train)
pred_bow = nb_bow.predict(X_test_bow)

# 3-2) TfidfVectorizer + NaiveBayes
tfidf = TfidfVectorizer()
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf  = tfidf.transform(X_test)

nb_tfidf = MultinomialNB(alpha=1.0)
nb_tfidf.fit(X_train_tfidf, y_train)
pred_tfidf = nb_tfidf.predict(X_test_tfidf)

# 3-3) CountVectorizer + RandomForest
rf_bow = RandomForestClassifier(random_state=42)
rf_bow.fit(X_train_bow, y_train)
pred_rf_bow = rf_bow.predict(X_test_bow)

# 3-4) TfidfVectorizer + RandomForest
rf_tfidf = RandomForestClassifier(random_state=42)
rf_tfidf.fit(X_train_tfidf, y_train)
pred_rf_tfidf = rf_tfidf.predict(X_test_tfidf)

import importlib.util
import sys

# 4-1) evaluate_utils 모듈 로드 (한 번만)
eval_name = "evaluate_utils"
eval_path = "/content/drive/MyDrive/evaluate_utils.py"

if eval_name in sys.modules:
    del sys.modules[eval_name]

spec2 = importlib.util.spec_from_file_location(eval_name, eval_path)
evaluate_utils = importlib.util.module_from_spec(spec2)
sys.modules[eval_name] = evaluate_utils
spec2.loader.exec_module(evaluate_utils)


# 4-2) 각 모델 결과 평가

# 4-2-A) BOW + NaiveBayes
evaluate_utils.evaluate_model(
    originals=orig_test,
    rewrites=pred_bow.tolist(),
    references=y_test,
    model_name="BoW + NaiveBayes"
)

# 4-2-B) TFIDF + NaiveBayes
evaluate_utils.evaluate_model(
    originals=orig_test,
    rewrites=pred_tfidf.tolist(),
    references=y_test,
    model_name="TFIDF + NaiveBayes"
)

# 4-2-C) BOW + RandomForest
evaluate_utils.evaluate_model(
    originals=orig_test,
    rewrites=pred_rf_bow.tolist(),
    references=y_test,
    model_name="BoW + RandomForest"
)

# 4-2-D) TFIDF + RandomForest
evaluate_utils.evaluate_model(
    originals=orig_test,
    rewrites=pred_rf_tfidf.tolist(),
    references=y_test,
    model_name="TFIDF + RandomForest"
)