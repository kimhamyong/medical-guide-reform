# -*- coding: utf-8 -*-
"""ML Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b-1_ol3P296fdSCQMXvoqtITwgnFZBxX
"""

from google.colab import drive # 구글 드라이브 연결
drive.mount('/content/drive')

csv_file_path = "./drive/MyDrive/combined_dataset.csv"
stop_words_path = "./drive/MyDrive/stopword.txt"

import pandas as pd
data = pd.read_csv(csv_file_path, sep=",")
data.head()

with open(stop_words_path, "r", encoding="UTF-8") as inFile:
  lines = inFile.readlines()

stop_words = set([])
for line in lines:
  stop_words.add(line.replace("\n",""))

!pip install kiwipiepy

from kiwipiepy import Kiwi
from kiwipiepy.utils import Stopwords
import re
# Kiwi의 객체 생성
kiwi = Kiwi()
stopwords = Stopwords()

def preprocessing(kiwi, review):
  # 한글이 아닌 단어는 지우고 " "으로 대체
  review_text = re.sub(r'[^ㄱ-ㅎ가-힣]+', ' ', review)

  token_list = kiwi.tokenize(review_text, stopwords=stopwords) # 받침 분리 안함 + stopwords
  # 초성에 해당하지 않는 단어만 clean_review에 들어갈 수 있게 함
  clean_review = []
  for token in token_list:
    if not token[1] == 'ETM' and not token[1] == 'EF':
      # if token[1] == 'EF': # 됩니다. 하십시오. 등은 되다. 하오. 로 전처리 하기위함
      #   clean_review[-1] += token[0][-1]
      # else:
      #   clean_review.append(token[0])
      clean_review.append(token[0])
  # 단어들을 ' '기준으로 이어 붙혀서 하나의 string 타입의 변수를 생성함
  clean_review = ' '.join(clean_review)

  # 전처리 완료된 문장을 return
  return clean_review.strip()

df = data
df['preprocessing_text'] = df['original_text'].apply(lambda t : preprocessing(kiwi, t))

df.head()

df.to_csv(path_or_buf="./drive/MyDrive/preprocessing_dataset.csv")

