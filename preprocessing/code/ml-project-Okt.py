# -*- coding: utf-8 -*-
"""Okt_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_pw7JJz3WvSuaBeiLH4BgS9ajn00iYjW
"""

# Java 설치 (konlpy는 Java를 필요로 함)
!apt-get install -y openjdk-8-jdk

import pandas as pd
import re
import json
from google.colab import drive

# Google Drive 마운트
drive.mount('/content/drive')

# 파일 경로 설정
csv_file_path = "/content/drive/MyDrive/combined_dataset.csv"
save_file_path = "/content/drive/MyDrive/Okt_preprocessed.csv"
term_dict_path = "/content/drive/MyDrive/term_dict.json"
style_rules_path = "/content/drive/MyDrive/style_rules.json"

# JSON 파일 불러오기
with open(term_dict_path, 'r', encoding='utf-8') as f:
    term_dict = json.load(f)

with open(style_rules_path, 'r', encoding='utf-8') as f:
    style_rules = json.load(f)

# 문체 변환 함수
def convert_style(text, style_rules):
    for formal, casual in style_rules.items():
        text = text.replace(formal, casual)
    return text

# 전문용어 치환 함수
def replace_terms(text, term_dict):
    for term, plain in term_dict.items():
        text = text.replace(term, plain)
    return text

# original_text 전처리 (문체 변환만)
def preprocess_style(text):
    text = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣.!?]', ' ', str(text))  # 한글+기초 문장부호만 남김
    sentences = re.split(r'(?<=[.!?])\s+', text)
    processed = [convert_style(s, style_rules) for s in sentences]
    return ' '.join(processed).strip()

# simple_text 전처리 (전문용어 + 문체 변환)
def preprocess_terms_and_style(text):
    text = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣.!?]', ' ', str(text))  # 한글+기초 문장부호만 남김
    sentences = re.split(r'(?<=[.!?])\s+', text)
    processed = []
    for sentence in sentences:
        sentence = replace_terms(sentence, term_dict)
        sentence = convert_style(sentence, style_rules)
        processed.append(sentence)
    return ' '.join(processed).strip()

# CSV 불러오기
data = pd.read_csv(csv_file_path, encoding='cp949')
print(f"원본 데이터 개수: {len(data)}")

# 전처리 수행
data['original_preprocessed'] = data['original_text'].apply(preprocess_style)
data['simple_preprocessed'] = data['simple_text'].apply(preprocess_terms_and_style)

# 공백 제거
before = len(data)
data = data[data['original_preprocessed'].str.strip() != '']
after = len(data)
print(f"공백 제거 후 데이터 개수: {after} (제거된 수: {before - after})")

# 저장
data.to_csv(save_file_path, index=False, encoding='utf-8-sig')
print("CSV 저장 완료:", save_file_path)